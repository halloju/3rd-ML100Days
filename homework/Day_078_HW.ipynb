{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請嘗試將 preproc_x 替換成以每筆資料的 min/max 進行標準化至 -1 ~ 1 間，再進行訓練\n",
    "2. 請嘗試將 mlp 疊更深 (e.g 5~10 層)，進行訓練後觀察 learning curve 的走勢\n",
    "3. (optional) 請改用 GPU 進行訓練 (如果你有 GPU 的話)，比較使用 CPU 與 GPU 的訓練速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  1 13:38:10 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 440.64.00    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce 940MX       On   | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   52C    P0    N/A /  N/A |    734MiB /  2004MiB |      2%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1243      G   /usr/lib/xorg/Xorg                            24MiB |\r\n",
      "|    0      1461      G   /usr/bin/gnome-shell                          46MiB |\r\n",
      "|    0      1662      G   /usr/lib/xorg/Xorg                           226MiB |\r\n",
      "|    0      1836      G   /usr/bin/gnome-shell                         121MiB |\r\n",
      "|    0      2212      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   242MiB |\r\n",
      "|    0     13658      G   ...log-file=/snap/spotify/41/usr/share/spo    64MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "\"\"\"\n",
    "Your code here (optional)\n",
    "確認硬體資源\n",
    "\"\"\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 請嘗試設定 GPU：os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "\"\"\"\n",
    "Your code here\n",
    "\"\"\"\n",
    "def preproc_x(x,flatten=True):\n",
    "    x=2*(((x - x.min()) / (x.max() - x.min()))-0.5)\n",
    "    if flatten:\n",
    "        x=x.reshape((len(x),-1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1]==1:\n",
    "        y=keras.utils.to_categorical(y,num_classes)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden_layer4 (Dense)        (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden_layer5 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,748,266\n",
      "Trainable params: 1,748,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Code Here\n",
    "建立你的神經網路\n",
    "\"\"\"\n",
    "def build_mlp(inputshape, output_units=10, num_neurons=[512,256,128,64,32]):\n",
    "    input_layer=keras.layers.Input(inputshape)\n",
    "    \n",
    "    for i,num_units in enumerate(num_neurons):\n",
    "        if i==0:\n",
    "            x=keras.layers.Dense(activation='relu', units=num_units, name='hidden_layer'+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x=keras.layers.Dense(activation='relu', units=num_units, name='hidden_layer'+str(i+1))(x)\n",
    "            \n",
    "    out=keras.layers.Dense(units=output_units, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model=keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model=build_mlp(x_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/wan-chu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.9630 - acc: 0.2806 - val_loss: 1.7852 - val_acc: 0.3627\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.7394 - acc: 0.3751 - val_loss: 1.7154 - val_acc: 0.3851\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.6474 - acc: 0.4100 - val_loss: 1.6030 - val_acc: 0.4318\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.5847 - acc: 0.4311 - val_loss: 1.5690 - val_acc: 0.4325\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.5232 - acc: 0.4553 - val_loss: 1.6108 - val_acc: 0.4258\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.4966 - acc: 0.4654 - val_loss: 1.5006 - val_acc: 0.4688\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.4631 - acc: 0.4772 - val_loss: 1.4784 - val_acc: 0.4713\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.4246 - acc: 0.4951 - val_loss: 1.4450 - val_acc: 0.4838\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.4024 - acc: 0.5001 - val_loss: 1.4297 - val_acc: 0.4873\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.3700 - acc: 0.5095 - val_loss: 1.4390 - val_acc: 0.4876\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3484 - acc: 0.5208 - val_loss: 1.4154 - val_acc: 0.4958\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3190 - acc: 0.5300 - val_loss: 1.4519 - val_acc: 0.4835\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.3027 - acc: 0.5347 - val_loss: 1.4053 - val_acc: 0.5023\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2773 - acc: 0.5446 - val_loss: 1.4066 - val_acc: 0.5063\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2544 - acc: 0.5525 - val_loss: 1.3633 - val_acc: 0.5178\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2262 - acc: 0.5657 - val_loss: 1.4025 - val_acc: 0.5086\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.2212 - acc: 0.5640 - val_loss: 1.3587 - val_acc: 0.5248\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1917 - acc: 0.5743 - val_loss: 1.3994 - val_acc: 0.5097\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1695 - acc: 0.5812 - val_loss: 1.4210 - val_acc: 0.5033\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1506 - acc: 0.5895 - val_loss: 1.3594 - val_acc: 0.5235\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1306 - acc: 0.5960 - val_loss: 1.3938 - val_acc: 0.5193\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.1229 - acc: 0.5988 - val_loss: 1.3493 - val_acc: 0.5290\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1013 - acc: 0.6099 - val_loss: 1.3660 - val_acc: 0.5269\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.0805 - acc: 0.6157 - val_loss: 1.3623 - val_acc: 0.5346\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.0583 - acc: 0.6226 - val_loss: 1.3993 - val_acc: 0.5293\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.0413 - acc: 0.6256 - val_loss: 1.3887 - val_acc: 0.5260\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.0225 - acc: 0.6366 - val_loss: 1.3959 - val_acc: 0.5315\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.0085 - acc: 0.6422 - val_loss: 1.4025 - val_acc: 0.5238\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.9775 - acc: 0.6525 - val_loss: 1.4110 - val_acc: 0.5326\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.9687 - acc: 0.6540 - val_loss: 1.4158 - val_acc: 0.5281\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.9642 - acc: 0.6574 - val_loss: 1.4371 - val_acc: 0.5256\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.9343 - acc: 0.6655 - val_loss: 1.4513 - val_acc: 0.5261\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.9194 - acc: 0.6712 - val_loss: 1.4662 - val_acc: 0.5251\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.9012 - acc: 0.6777 - val_loss: 1.4669 - val_acc: 0.5218\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.8818 - acc: 0.6849 - val_loss: 1.4383 - val_acc: 0.5305\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.8654 - acc: 0.6917 - val_loss: 1.4886 - val_acc: 0.5267\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.8494 - acc: 0.6970 - val_loss: 1.4852 - val_acc: 0.5323\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.8305 - acc: 0.7027 - val_loss: 1.5364 - val_acc: 0.5228\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.8163 - acc: 0.7084 - val_loss: 1.5351 - val_acc: 0.5286\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.8097 - acc: 0.7099 - val_loss: 1.5020 - val_acc: 0.5278\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.7863 - acc: 0.7194 - val_loss: 1.5669 - val_acc: 0.5277\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.7749 - acc: 0.7234 - val_loss: 1.6500 - val_acc: 0.5210\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.7687 - acc: 0.7255 - val_loss: 1.5915 - val_acc: 0.5260\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.7558 - acc: 0.7306 - val_loss: 1.6226 - val_acc: 0.5188\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 0.7285 - acc: 0.7402 - val_loss: 1.6325 - val_acc: 0.5278\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.7090 - acc: 0.7458 - val_loss: 1.6761 - val_acc: 0.5275\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.7027 - acc: 0.7481 - val_loss: 1.6729 - val_acc: 0.5284\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.6936 - acc: 0.7516 - val_loss: 1.7322 - val_acc: 0.5204\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.6841 - acc: 0.7544 - val_loss: 1.7774 - val_acc: 0.5155\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.6652 - acc: 0.7623 - val_loss: 1.8346 - val_acc: 0.5095\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.6585 - acc: 0.7646 - val_loss: 1.8231 - val_acc: 0.5181\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.6462 - acc: 0.7704 - val_loss: 1.7973 - val_acc: 0.5227\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 0.6330 - acc: 0.7734 - val_loss: 1.8311 - val_acc: 0.5241\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.6363 - acc: 0.7724 - val_loss: 1.8822 - val_acc: 0.5172\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.6056 - acc: 0.7831 - val_loss: 1.8173 - val_acc: 0.5237\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.6088 - acc: 0.7834 - val_loss: 1.9034 - val_acc: 0.5005\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.5985 - acc: 0.7844 - val_loss: 1.9060 - val_acc: 0.5203\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.5956 - acc: 0.7877 - val_loss: 1.9359 - val_acc: 0.5177\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.5712 - acc: 0.7963 - val_loss: 1.9378 - val_acc: 0.5185\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.5581 - acc: 0.8012 - val_loss: 2.0432 - val_acc: 0.5026\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.5559 - acc: 0.8013 - val_loss: 2.0031 - val_acc: 0.5157\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.5644 - acc: 0.7971 - val_loss: 2.1113 - val_acc: 0.5089\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 0.5403 - acc: 0.8079 - val_loss: 2.0840 - val_acc: 0.5162\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.5323 - acc: 0.8101 - val_loss: 2.0539 - val_acc: 0.5119\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.5137 - acc: 0.8165 - val_loss: 2.1000 - val_acc: 0.5129\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.5099 - acc: 0.8193 - val_loss: 2.1016 - val_acc: 0.5198\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.5010 - acc: 0.8219 - val_loss: 2.1613 - val_acc: 0.5172\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.4982 - acc: 0.8220 - val_loss: 2.2511 - val_acc: 0.5117\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 0.4839 - acc: 0.8277 - val_loss: 2.1731 - val_acc: 0.5103\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.4823 - acc: 0.8289 - val_loss: 2.2088 - val_acc: 0.5179\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.4713 - acc: 0.8308 - val_loss: 2.2515 - val_acc: 0.5108\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 7s 146us/step - loss: 0.4693 - acc: 0.8329 - val_loss: 2.3094 - val_acc: 0.5082\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.4588 - acc: 0.8357 - val_loss: 2.3050 - val_acc: 0.5145\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4478 - acc: 0.8407 - val_loss: 2.2766 - val_acc: 0.5202\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4506 - acc: 0.8387 - val_loss: 2.4497 - val_acc: 0.5049\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.4533 - acc: 0.8389 - val_loss: 2.3787 - val_acc: 0.5047\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4351 - acc: 0.8441 - val_loss: 2.3796 - val_acc: 0.5043\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4161 - acc: 0.8500 - val_loss: 2.4036 - val_acc: 0.5078\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 0.4109 - acc: 0.8529 - val_loss: 2.5286 - val_acc: 0.5095\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.4327 - acc: 0.8456 - val_loss: 2.5650 - val_acc: 0.5021\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4250 - acc: 0.8486 - val_loss: 2.3987 - val_acc: 0.5068\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4066 - acc: 0.8566 - val_loss: 2.4881 - val_acc: 0.5007\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3984 - acc: 0.8583 - val_loss: 2.5430 - val_acc: 0.5073\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.4004 - acc: 0.8569 - val_loss: 2.5460 - val_acc: 0.4998\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.3903 - acc: 0.8612 - val_loss: 2.6103 - val_acc: 0.5075\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3778 - acc: 0.8664 - val_loss: 2.5419 - val_acc: 0.4993\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.3781 - acc: 0.8658 - val_loss: 2.6026 - val_acc: 0.5058\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 0.3972 - acc: 0.8573 - val_loss: 2.7106 - val_acc: 0.5003\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 8s 150us/step - loss: 0.3733 - acc: 0.8649 - val_loss: 2.7109 - val_acc: 0.5012\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 0.3589 - acc: 0.8721 - val_loss: 2.6464 - val_acc: 0.5102\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.3552 - acc: 0.8708 - val_loss: 2.7317 - val_acc: 0.5019\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3790 - acc: 0.8642 - val_loss: 2.7664 - val_acc: 0.4982\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.3539 - acc: 0.8730 - val_loss: 2.7633 - val_acc: 0.5042\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 0.3365 - acc: 0.8804 - val_loss: 2.8190 - val_acc: 0.5059\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 0.3373 - acc: 0.8794 - val_loss: 2.8013 - val_acc: 0.5021\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3534 - acc: 0.8739 - val_loss: 2.8123 - val_acc: 0.5141\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3557 - acc: 0.8729 - val_loss: 2.8354 - val_acc: 0.5063\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3377 - acc: 0.8784 - val_loss: 2.8333 - val_acc: 0.5093\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 0.3378 - acc: 0.8793 - val_loss: 2.8725 - val_acc: 0.5082\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 0.3554 - acc: 0.8726 - val_loss: 2.9861 - val_acc: 0.5065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc791622518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
